import sys
import pickle
import re
import numpy as np
from scipy.sparse import hstack

sys.stdout.reconfigure(encoding='utf-8')  # âœ… Ensure correct encoding

print("ğŸ“Œ predict.py script started", flush=True)

# âœ… Step 1: Define URL Cleaning Function
def clean_url(url):
    url = url.lower()
    url = re.sub(r"https?://", "", url)
    url = re.sub(r"www\.", "", url)
    url = re.sub(r"[^a-zA-Z0-9\-_.@]", " ", url)
    url = re.sub(r"\s+", " ", url).strip()
    return url

# âœ… Step 2: Load Model and Vectorizer
try:
    print("ğŸ“Œ Loading Model...", flush=True)
    with open("phishing_model.pkl", "rb") as model_file:
        model = pickle.load(model_file)

    with open("vectorizer.pkl", "rb") as vectorizer_file:
        vectorizer = pickle.load(vectorizer_file)

    print("âœ… Model and vectorizer loaded successfully.", flush=True)

except Exception as e:
    print(f"âŒ Error loading model: {str(e)}", flush=True)
    sys.exit(1)

# âœ… Step 3: Get Input URL
if len(sys.argv) < 2:
    print("âŒ Error: No URL provided", flush=True)
    sys.exit(1)

url = sys.argv[1]
print(f"ğŸ“Œ Received URL: {url}", flush=True)

# âœ… Step 4: Apply Preprocessing
cleaned_url = clean_url(url)
print(f"ğŸ”„ Processing: {cleaned_url}", flush=True)

# âœ… Step 5: Convert URL to Features
try:
    print("ğŸ“Œ Vectorizing URL...", flush=True)
    url_tfidf = vectorizer.transform([cleaned_url])

    # Extract Additional Features
    url_features = np.array([[len(cleaned_url), cleaned_url.count('.'), cleaned_url.count('-')]])

    # âœ… Combine Features
    url_combined = hstack([url_tfidf, url_features])

    print("ğŸ“Œ Running Model Prediction...", flush=True)
    prediction = model.predict(url_combined)[0]

    print("âœ… Prediction Completed.", flush=True)
    print("1" if prediction == 1 else "0", flush=True)

except Exception as e:
    print(f"âŒ Prediction Error: {str(e)}", flush=True)
    sys.exit(1)
